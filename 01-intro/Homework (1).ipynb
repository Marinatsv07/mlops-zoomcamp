{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "32a5a607",
      "metadata": {
        "id": "32a5a607"
      },
      "outputs": [],
      "source": [
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cdd2cea3",
      "metadata": {
        "id": "cdd2cea3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4d0edf66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4d0edf66",
        "outputId": "67504f74-b12a-4bed-e486-6d93ee436d8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "pd.__version__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "69755272",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "69755272",
        "outputId": "aa355a2c-ba6c-4100-92da-3c319f632202"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.2.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "sklearn.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "59345406",
      "metadata": {
        "id": "59345406"
      },
      "outputs": [],
      "source": [
        "df = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "bad1ca84",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bad1ca84",
        "outputId": "2b9a8061-4210-4fea-b080-4161cc932bdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (14.0.2)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a9cb965c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9cb965c",
        "outputId": "d2c663be-517e-4d16-d612-c59b3f9b42c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n"
          ]
        }
      ],
      "source": [
        "col=len(df.columns)\n",
        "print(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8ebf7be1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ebf7be1",
        "outputId": "7e474e49-09b9-4942-bce1-4b37f72aa18d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard deviation of trips duration in January (in minutes): 34.851053592212814\n",
            "Fraction of records left after dropping outliers: 0.9778326020432945\n",
            "Dimensionality of the feature matrix (number of columns): 518\n",
            "RMSE on the train data: 7.948999928312118\n"
          ]
        }
      ],
      "source": [
        "# Calculate 'duration' as the difference between drop-off and pick-up times\n",
        "df['duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime'])\n",
        "\n",
        "# Convert duration from timedelta to minutes\n",
        "df['duration_min'] = df['duration'].dt.total_seconds() / 60\n",
        "\n",
        "# Calculate the standard deviation of trip durations in January (in minutes)\n",
        "std_duration_january = df['duration_min'].std()\n",
        "print(\"Standard deviation of trips duration in January (in minutes):\", std_duration_january)\n",
        "\n",
        "# Filtering df to remove outliers, keeping only durations between 1 and 60 minutes\n",
        "original_count = len(df)\n",
        "df_filtered = df[(df['duration_min'] >= 1) & (df['duration_min'] <= 60)].copy()\n",
        "filtered_count = len(df_filtered)\n",
        "\n",
        "# Determine what fraction of records remains after dropping outliers\n",
        "fraction_left = filtered_count / original_count\n",
        "print(\"Fraction of records left after dropping outliers:\", fraction_left)\n",
        "\n",
        "# Convert location IDs to strings\n",
        "df_filtered['PULocationID'] = df_filtered['PULocationID'].astype(str)\n",
        "df_filtered['DOLocationID'] = df_filtered['DOLocationID'].astype(str)\n",
        "\n",
        "# Use only the filtered duration in minutes for further processing\n",
        "df_filtered['duration'] = df_filtered['duration_min']\n",
        "\n",
        "# Convert DataFrame to a list of dictionaries for feature encoding\n",
        "data_dicts = df_filtered[['PULocationID', 'DOLocationID']].to_dict(orient='records')\n",
        "\n",
        "# Create and apply DictVectorizer\n",
        "vectorizer = DictVectorizer(sparse=True)\n",
        "feature_matrix = vectorizer.fit_transform(data_dicts)\n",
        "\n",
        "# Number of columns in the feature matrix\n",
        "print(\"Dimensionality of the feature matrix (number of columns):\", feature_matrix.shape[1])\n",
        "\n",
        "# Target variable\n",
        "y = df_filtered['duration']\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_matrix, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training data\n",
        "y_train_pred = model.predict(X_train)\n",
        "\n",
        "# Calculate RMSE on the training data\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "print(\"RMSE on the train data:\", rmse_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6c60c0fa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c60c0fa",
        "outputId": "0722fa38-2db2-420b-854a-4c06ecd2559b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE on the validation data (February 2023): 8.124011701161189\n"
          ]
        }
      ],
      "source": [
        "# Load the February 2023 data\n",
        "df_feb = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-02.parquet')\n",
        "\n",
        "# Calculate 'duration' as the difference between drop-off and pick-up times\n",
        "df_feb['duration'] = (df_feb['tpep_dropoff_datetime'] - df_feb['tpep_pickup_datetime'])\n",
        "\n",
        "# Convert duration from timedelta to minutes\n",
        "df_feb['duration_min'] = df_feb['duration'].dt.total_seconds() / 60\n",
        "\n",
        "# Filter df_feb to remove outliers, keeping only durations between 1 and 60 minutes\n",
        "df_feb_filtered = df_feb[(df_feb['duration_min'] >= 1) & (df_feb['duration_min'] <= 60)].copy()\n",
        "\n",
        "# Convert location IDs to strings\n",
        "df_feb_filtered['PULocationID'] = df_feb_filtered['PULocationID'].astype(str)\n",
        "df_feb_filtered['DOLocationID'] = df_feb_filtered['DOLocationID'].astype(str)\n",
        "\n",
        "# Prepare the validation dataset for prediction using the same DictVectorizer\n",
        "# (assuming 'vectorizer' has been fitted with the training data)\n",
        "data_dicts_feb = df_feb_filtered[['PULocationID', 'DOLocationID']].to_dict(orient='records')\n",
        "X_feb = vectorizer.transform(data_dicts_feb)\n",
        "\n",
        "# Target variable for validation dataset\n",
        "y_feb = df_feb_filtered['duration_min']\n",
        "\n",
        "# Use the already trained model to make predictions on the February data\n",
        "y_feb_pred = model.predict(X_feb)\n",
        "\n",
        "# Calculate RMSE on the February data\n",
        "rmse_feb = np.sqrt(mean_squared_error(y_feb, y_feb_pred))\n",
        "print(\"RMSE on the validation data (February 2023):\", rmse_feb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fbcdaae8",
      "metadata": {
        "id": "fbcdaae8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}