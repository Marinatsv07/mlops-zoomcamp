{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a5a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdd2cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d0edf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69755272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59345406",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bad1ca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9cb965c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "col=len(df.columns)\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ebf7be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of trips duration in January (in minutes): 34.851053592192876\n",
      "Fraction of records left after dropping outliers: 0.9778326020432945\n",
      "Dimensionality of the feature matrix (number of columns): 518\n",
      "RMSE on the train data: 7.948999308349224\n"
     ]
    }
   ],
   "source": [
    "# Calculate 'duration' as the difference between drop-off and pick-up times\n",
    "df['duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime'])\n",
    "\n",
    "# Convert duration from timedelta to minutes\n",
    "df['duration_min'] = df['duration'].dt.total_seconds() / 60\n",
    "\n",
    "# Calculate the standard deviation of trip durations in January (in minutes)\n",
    "std_duration_january = df['duration_min'].std()\n",
    "print(\"Standard deviation of trips duration in January (in minutes):\", std_duration_january)\n",
    "\n",
    "# Filtering df to remove outliers, keeping only durations between 1 and 60 minutes\n",
    "original_count = len(df)\n",
    "df_filtered = df[(df['duration_min'] >= 1) & (df['duration_min'] <= 60)].copy()\n",
    "filtered_count = len(df_filtered)\n",
    "\n",
    "# Determine what fraction of records remains after dropping outliers\n",
    "fraction_left = filtered_count / original_count\n",
    "print(\"Fraction of records left after dropping outliers:\", fraction_left)\n",
    "\n",
    "# Convert location IDs to strings\n",
    "df_filtered['PULocationID'] = df_filtered['PULocationID'].astype(str)\n",
    "df_filtered['DOLocationID'] = df_filtered['DOLocationID'].astype(str)\n",
    "\n",
    "# Use only the filtered duration in minutes for further processing\n",
    "df_filtered['duration'] = df_filtered['duration_min']\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries for feature encoding\n",
    "data_dicts = df_filtered[['PULocationID', 'DOLocationID']].to_dict(orient='records')\n",
    "\n",
    "# Create and apply DictVectorizer\n",
    "vectorizer = DictVectorizer(sparse=True)\n",
    "feature_matrix = vectorizer.fit_transform(data_dicts)\n",
    "\n",
    "# Number of columns in the feature matrix\n",
    "print(\"Dimensionality of the feature matrix (number of columns):\", feature_matrix.shape[1])\n",
    "\n",
    "# Target variable\n",
    "y = df_filtered['duration']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_matrix, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training data\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate RMSE on the training data\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "print(\"RMSE on the train data:\", rmse_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c60c0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the validation data (February 2023): 8.124017135620836\n"
     ]
    }
   ],
   "source": [
    "# Load the February 2023 data\n",
    "df_feb = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-02.parquet')\n",
    "\n",
    "# Calculate 'duration' as the difference between drop-off and pick-up times\n",
    "df_feb['duration'] = (df_feb['tpep_dropoff_datetime'] - df_feb['tpep_pickup_datetime'])\n",
    "\n",
    "# Convert duration from timedelta to minutes\n",
    "df_feb['duration_min'] = df_feb['duration'].dt.total_seconds() / 60\n",
    "\n",
    "# Filter df_feb to remove outliers, keeping only durations between 1 and 60 minutes\n",
    "df_feb_filtered = df_feb[(df_feb['duration_min'] >= 1) & (df_feb['duration_min'] <= 60)].copy()\n",
    "\n",
    "# Convert location IDs to strings\n",
    "df_feb_filtered['PULocationID'] = df_feb_filtered['PULocationID'].astype(str)\n",
    "df_feb_filtered['DOLocationID'] = df_feb_filtered['DOLocationID'].astype(str)\n",
    "\n",
    "# Prepare the validation dataset for prediction using the same DictVectorizer\n",
    "# (assuming 'vectorizer' has been fitted with the training data)\n",
    "data_dicts_feb = df_feb_filtered[['PULocationID', 'DOLocationID']].to_dict(orient='records')\n",
    "X_feb = vectorizer.transform(data_dicts_feb)\n",
    "\n",
    "# Target variable for validation dataset\n",
    "y_feb = df_feb_filtered['duration_min']\n",
    "\n",
    "# Use the already trained model to make predictions on the February data\n",
    "y_feb_pred = model.predict(X_feb)\n",
    "\n",
    "# Calculate RMSE on the February data\n",
    "rmse_feb = np.sqrt(mean_squared_error(y_feb, y_feb_pred))\n",
    "print(\"RMSE on the validation data (February 2023):\", rmse_feb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcdaae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
